{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe8317c",
   "metadata": {},
   "source": [
    "# Import ratings data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea913ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leuch\\AppData\\Local\\Temp\\ipykernel_19780\\2626815215.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  raw_data = pd.read_csv(\"./data/Movielens100/u.data\", sep = None, names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 2., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "raw_data = pd.read_csv(\"./data/Movielens100/u.data\", sep = None, names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
    "raw_data = raw_data.loc[:, raw_data.columns != \"timestamp\"]\n",
    "#make indices start at 0\n",
    "raw_data[\"userId\"] -= 1\n",
    "raw_data[\"movieId\"] -= 1\n",
    "#make ratings center around 0\n",
    "raw_data[\"rating\"] -= 3\n",
    "\n",
    "# create (943, 1682) matrix of user ratings per movie\n",
    "user_ratings = pd.DataFrame(np.zeros((943,1682)))\n",
    "for i in raw_data.index:\n",
    "    user_ratings[raw_data[\"movieId\"][i]][raw_data[\"userId\"][i]] = raw_data[\"rating\"][i]\n",
    "user_ratings = user_ratings.to_numpy() \n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bccf70",
   "metadata": {},
   "source": [
    "# Import user information matrix I made\n",
    "\n",
    "First column is normalized age, second column is sex, the rest are the average ratings per genre. Genres are listed in u.genre file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44118cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.824422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.528577</td>\n",
       "      <td>0.163282</td>\n",
       "      <td>-0.643886</td>\n",
       "      <td>-0.442094</td>\n",
       "      <td>-1.133953</td>\n",
       "      <td>0.682175</td>\n",
       "      <td>-0.240302</td>\n",
       "      <td>-0.297957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528577</td>\n",
       "      <td>-0.499749</td>\n",
       "      <td>-0.384440</td>\n",
       "      <td>-0.586232</td>\n",
       "      <td>-0.470922</td>\n",
       "      <td>0.624520</td>\n",
       "      <td>0.682175</td>\n",
       "      <td>0.365074</td>\n",
       "      <td>-0.067338</td>\n",
       "      <td>-0.442094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.554043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>0.549569</td>\n",
       "      <td>-0.003917</td>\n",
       "      <td>-0.419032</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>1.241427</td>\n",
       "      <td>0.411197</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.142289</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.280661</td>\n",
       "      <td>1.933286</td>\n",
       "      <td>-0.142289</td>\n",
       "      <td>0.411197</td>\n",
       "      <td>-0.280661</td>\n",
       "      <td>-0.557404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.906438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-1.036383</td>\n",
       "      <td>-0.238085</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-1.355702</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.238085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.717064</td>\n",
       "      <td>-1.036383</td>\n",
       "      <td>-0.876723</td>\n",
       "      <td>-0.238085</td>\n",
       "      <td>-0.238085</td>\n",
       "      <td>-0.876723</td>\n",
       "      <td>-2.154000</td>\n",
       "      <td>-0.717064</td>\n",
       "      <td>-0.557404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.824422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>1.621949</td>\n",
       "      <td>0.065268</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>1.933286</td>\n",
       "      <td>1.621949</td>\n",
       "      <td>0.065268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.246068</td>\n",
       "      <td>0.065268</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.687941</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>2.555958</td>\n",
       "      <td>0.376605</td>\n",
       "      <td>-0.557404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.086278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.506365</td>\n",
       "      <td>-0.149094</td>\n",
       "      <td>-0.149094</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>-1.374024</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.149094</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.608443</td>\n",
       "      <td>-0.455327</td>\n",
       "      <td>-1.220908</td>\n",
       "      <td>-0.353249</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-1.220908</td>\n",
       "      <td>0.310254</td>\n",
       "      <td>-0.608443</td>\n",
       "      <td>-0.404288</td>\n",
       "      <td>-0.608443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>-0.660390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>2.193939</td>\n",
       "      <td>0.166634</td>\n",
       "      <td>-0.412597</td>\n",
       "      <td>-0.412597</td>\n",
       "      <td>2.773170</td>\n",
       "      <td>0.021826</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412597</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.412597</td>\n",
       "      <td>-0.412597</td>\n",
       "      <td>2.049132</td>\n",
       "      <td>0.745864</td>\n",
       "      <td>1.325094</td>\n",
       "      <td>0.311441</td>\n",
       "      <td>-0.557404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>-0.168294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>0.284045</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.304969</td>\n",
       "      <td>-0.052535</td>\n",
       "      <td>1.293784</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.304969</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.473259</td>\n",
       "      <td>-0.220824</td>\n",
       "      <td>0.536480</td>\n",
       "      <td>-0.473259</td>\n",
       "      <td>0.031610</td>\n",
       "      <td>-0.220824</td>\n",
       "      <td>-0.557404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>-1.152486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>1.933286</td>\n",
       "      <td>1.310613</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.376605</td>\n",
       "      <td>1.933286</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.246068</td>\n",
       "      <td>0.065268</td>\n",
       "      <td>0.065268</td>\n",
       "      <td>1.621949</td>\n",
       "      <td>1.621949</td>\n",
       "      <td>0.065268</td>\n",
       "      <td>-0.557404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>1.143963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>1.301320</td>\n",
       "      <td>1.208383</td>\n",
       "      <td>0.093149</td>\n",
       "      <td>1.022511</td>\n",
       "      <td>1.673064</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371532</td>\n",
       "      <td>-0.371532</td>\n",
       "      <td>-0.371532</td>\n",
       "      <td>0.093149</td>\n",
       "      <td>0.279022</td>\n",
       "      <td>1.673064</td>\n",
       "      <td>0.093149</td>\n",
       "      <td>1.301320</td>\n",
       "      <td>1.022511</td>\n",
       "      <td>-0.092723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>-0.988454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>-0.157115</td>\n",
       "      <td>-0.512928</td>\n",
       "      <td>-0.646357</td>\n",
       "      <td>-0.646357</td>\n",
       "      <td>0.421081</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601881</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>-0.157115</td>\n",
       "      <td>-0.423974</td>\n",
       "      <td>-0.468451</td>\n",
       "      <td>-0.290545</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>0.732417</td>\n",
       "      <td>-0.201591</td>\n",
       "      <td>-0.735311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1         2         3         4         5         6  \\\n",
       "0   -0.824422  1.0 -0.528577  0.163282 -0.643886 -0.442094 -1.133953   \n",
       "1    1.554043  0.0 -0.557404  0.549569 -0.003917 -0.419032 -0.557404   \n",
       "2   -0.906438  1.0 -0.557404 -1.036383 -0.238085 -0.557404 -0.557404   \n",
       "3   -0.824422  1.0 -0.557404  1.621949  0.065268 -0.557404 -0.557404   \n",
       "4   -0.086278  0.0 -0.506365 -0.149094 -0.149094  0.004022 -1.374024   \n",
       "..        ...  ...       ...       ...       ...       ...       ...   \n",
       "938 -0.660390  0.0 -0.557404  2.193939  0.166634 -0.412597 -0.412597   \n",
       "939 -0.168294  1.0 -0.557404  0.284045 -0.557404 -0.304969 -0.052535   \n",
       "940 -1.152486  1.0 -0.557404  1.933286  1.310613  0.999277  0.376605   \n",
       "941  1.143963  0.0 -0.557404  1.301320  1.208383  0.093149  1.022511   \n",
       "942 -0.988454  1.0 -0.557404  0.999277 -0.157115 -0.512928 -0.646357   \n",
       "\n",
       "            7         8         9  ...        11        12        13  \\\n",
       "0    0.682175 -0.240302 -0.297957  ... -0.528577 -0.499749 -0.384440   \n",
       "1    1.241427  0.411197 -0.557404  ... -0.557404 -0.142289 -0.557404   \n",
       "2   -1.355702 -0.557404 -0.238085  ... -0.557404 -0.717064 -1.036383   \n",
       "3    1.933286  1.621949  0.065268  ... -0.557404 -0.557404 -0.246068   \n",
       "4   -0.557404 -0.149094 -0.557404  ... -0.608443 -0.455327 -1.220908   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "938  2.773170  0.021826 -0.557404  ... -0.412597 -0.557404 -0.557404   \n",
       "939  1.293784  0.199900 -0.557404  ... -0.557404 -0.304969 -0.557404   \n",
       "940  1.933286 -0.557404 -0.557404  ... -0.557404 -0.557404 -0.557404   \n",
       "941  1.673064 -0.557404 -0.557404  ... -0.371532 -0.371532 -0.371532   \n",
       "942 -0.646357  0.421081 -0.557404  ... -0.601881 -0.557404 -0.157115   \n",
       "\n",
       "           14        15        16        17        18        19        20  \n",
       "0   -0.586232 -0.470922  0.624520  0.682175  0.365074 -0.067338 -0.442094  \n",
       "1   -0.557404 -0.280661  1.933286 -0.142289  0.411197 -0.280661 -0.557404  \n",
       "2   -0.876723 -0.238085 -0.238085 -0.876723 -2.154000 -0.717064 -0.557404  \n",
       "3    0.065268  0.999277  0.687941  0.999277  2.555958  0.376605 -0.557404  \n",
       "4   -0.353249 -0.557404 -1.220908  0.310254 -0.608443 -0.404288 -0.608443  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "938 -0.412597 -0.412597  2.049132  0.745864  1.325094  0.311441 -0.557404  \n",
       "939 -0.473259 -0.220824  0.536480 -0.473259  0.031610 -0.220824 -0.557404  \n",
       "940 -0.246068  0.065268  0.065268  1.621949  1.621949  0.065268 -0.557404  \n",
       "941  0.093149  0.279022  1.673064  0.093149  1.301320  1.022511 -0.092723  \n",
       "942 -0.423974 -0.468451 -0.290545 -0.557404  0.732417 -0.201591 -0.735311  \n",
       "\n",
       "[943 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info = pd.read_csv(\"./data/user_info.csv\", index_col=0)\n",
    "user_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b4033",
   "metadata": {},
   "source": [
    "# Create training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc16b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the final labels as is\n",
    "labels = user_ratings\n",
    "\n",
    "#The features will be 80% of the users ratings concatenated with the user_info\n",
    "\n",
    "# create a mask of 0 and 1 values where half are 0 and 0.8 (Default) are 1. \n",
    "#The ratio of masked values is something that can and should be optimized. \n",
    "mask_magnitude = 1.3\n",
    "random_mask = np.clip((np.random.randn(1682) + mask_magnitude).round(), a_max = 1, a_min = 0)\n",
    "\n",
    "user_ratings *= random_mask\n",
    "features = np.concatenate((user_info, user_ratings), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e5ebe",
   "metadata": {},
   "source": [
    "# Create model and dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471c75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn \n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "device = \"cuda\"\n",
    "\n",
    "class MovielensDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # input_noise The variance of the noise \n",
    "        \n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "#noise layers for regularization\n",
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, stddev):\n",
    "        super().__init__()\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return x + torch.autograd.Variable(torch.randn(x.size()).cuda() * self.stddev)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# This is a standard VAE but using MSE as the reconstruction term. \n",
    "\n",
    "#Actually just rename this out and make loss function a parameter\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, recon_loss_fcn = \"MSE\", residual_user_info = False, dropout_rate = 0.0, nonLinearity = \"LeakyRelu\", fixed_variance = False, deterministicEval = False, noiseLayerStd = 0.2, hidden_size =1024, latent_size = 512):\n",
    "        #fixed variance is false if regular or equal to the value of the parameter\n",
    "        super().__init__()\n",
    "        \n",
    "        if nonLinearity == \"LeakyRelu\":\n",
    "            nonLin = nn.LeakyReLU\n",
    "        elif nonLinearity == \"Relu\":\n",
    "            nonLin = nn.ReLU\n",
    "        elif nonLinearity == \"Tanh\":\n",
    "            nonLin = nn.Tanh\n",
    "        elif nonLinearity == \"Sigmoid\":\n",
    "            nonLin = nn.Sigmoid\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            #Encoder\n",
    "            nn.Linear(1703, hidden_size),\n",
    "            nonLin(),\n",
    "            GaussianNoise(noiseLayerStd),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nonLin(),\n",
    "            GaussianNoise(noiseLayerStd),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            #Decoder\n",
    "            nn.Linear(latent_size,hidden_size),\n",
    "            nonLin(),\n",
    "            GaussianNoise(noiseLayerStd),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        # distribution parameters\n",
    "        self.fc_mu = nn.Linear(hidden_size, latent_size)\n",
    "        self.fc_var = nn.Linear(hidden_size, latent_size)\n",
    "        final_layer_size = hidden_size\n",
    "        self.residual_user_info = residual_user_info\n",
    "        if self.residual_user_info == True:\n",
    "            final_layer_size += 22\n",
    "        self.final_layer = nn.Linear(final_layer_size,1682)\n",
    "        self.final_activation = nn.Tanh()\n",
    "        \n",
    "        \n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "        #for evaluation purposes\n",
    "        self.test_mse = 1000\n",
    "        self.mse_loss_fcn = nn.MSELoss()\n",
    "        self.recon_loss_fcn = recon_loss_fcn\n",
    "        \n",
    "        # for varieties of VAE\n",
    "        self.fixed_variance = fixed_variance\n",
    "        self.deterministicEval = deterministicEval\n",
    "        \n",
    "    def gaussian_likelihood(self, x_hat, logscale, x):\n",
    "        scale = torch.exp(logscale)\n",
    "        mean = x_hat\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "\n",
    "        # measure prob of seeing data under p(x|z)\n",
    "        log_pxz = dist.log_prob(x)\n",
    "        return log_pxz.sum(dim=1)\n",
    "    \n",
    "    def kl_divergence(self, z, mu, std):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded) if self.fixed_variance == False else self.fc_var(x_encoded) / self.fc_var(x_encoded) * self.fixed_variance\n",
    "        \n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        if self.training == False and self.deterministicEval == True:\n",
    "            std = std * 0\n",
    "    \n",
    "        #perform the kernel trick to allow for backprop through sampling\n",
    "        epsilon = torch.distributions.Normal(0, 1).rsample()\n",
    "        z = mu + epsilon * std\n",
    "        # decoded\n",
    "        if self.residual_user_info == True:\n",
    "            final_layer_input = torch.concat((self.decoder(z), x[:, :22]), axis = 1)\n",
    "        else:\n",
    "            final_layer_input = self.decoder(z)\n",
    "        ratings = self.final_layer(final_layer_input) \n",
    "        ratings = self.final_activation(ratings) * 2\n",
    "        return ratings, z, mu, std\n",
    "    \n",
    "    def vae_loss(self, x_hat, x, z, mu, std):\n",
    "        # reconstruction loss\n",
    "        if self.recon_loss_fcn == \"MSE\":\n",
    "            recon_loss = self.mse_loss_fcn(x_hat, x) * 10000\n",
    "        else: \n",
    "            recon_loss = -self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "        \n",
    "        # kl\n",
    "        if self.training == True and self.fixed_variance == False:\n",
    "            kl = self.kl_divergence(z, mu, std)\n",
    "        else:\n",
    "            kl = 0\n",
    "        \n",
    "        # elbo\n",
    "        elbo = (kl + recon_loss).mean()\n",
    "\n",
    "        return elbo\n",
    "\n",
    "def train(dataloader, model,  optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "        \n",
    "        #compute prediction error\n",
    "        pred, z, mu, std = model(X)\n",
    "        loss = model.vae_loss(pred, y, z, mu, std)\n",
    "        mse_loss = mse_loss_fcn(pred, y)\n",
    "        \n",
    "        #Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 100 == 0 and batch % 64 == 0:\n",
    "            loss , current = loss.item(), (batch+1) * len(X)\n",
    "            #print(\"Epoch : \" + str(epoch))\n",
    "            #print(f\"loss: {loss:>7f}\")\n",
    "            #print(f\"MSE loss: {mse_loss:>7f}\")\n",
    "            losses.append(loss)\n",
    "            mse_losses.append(mse_loss.item())\n",
    "\n",
    "def test(dataloader, model, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches= len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, test_mse_loss = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            \n",
    "            \n",
    "            pred, z, mu, std = model(X)\n",
    "            test_loss += model.vae_loss(pred, y, z, mu, std).item()\n",
    "            test_mse_loss += mse_loss_fcn(pred, y)\n",
    "    test_loss /= num_batches\n",
    "    test_mse_loss /= num_batches\n",
    "    if epoch % 100 ==0:\n",
    "        test_losses.append(test_loss)\n",
    "        #Calculate RMSE on just the rated ones like the papers do \n",
    "        nonzero_indices = y.nonzero().split( 1, dim=1)\n",
    "        relevant_rmse = torch.sqrt(mse_loss_fcn(y[nonzero_indices], pred[nonzero_indices]))#torch.sqrt((y[nonzero_indices] - pred[nonzero_indices] ** 2).mean())\n",
    "        \n",
    "        #print(f\"Test Error: \\n Avg Loss : {test_loss:>8f} \")\n",
    "        #print(f\" Test MSE loss: {test_mse_loss:>7f}\")\n",
    "        #print(\"Relevant RMSE loss: \" + str(relevant_rmse.item()))\n",
    "        test_mse_losses.append(test_mse_loss.item())\n",
    "        model.test_mse = relevant_rmse.item()\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7b06a",
   "metadata": {},
   "source": [
    "# Load model and test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ba7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: \n",
      "tensor(0.8383, device='cuda:0', dtype=torch.float64)\n",
      "Precision and Recall: \n",
      "(0.7470588235294118, 0.7298850574712644, 0.7383720930232558, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "model = VAE(recon_loss_fcn = \"MSE\", residual_user_info = True, nonLinearity = \"Tanh\", dropout_rate = 0.1, fixed_variance = 0.3, deterministicEval = True, noiseLayerStd = 0.0, hidden_size = 4096, latent_size = 512 ).to(device)\n",
    "model.load_state_dict(torch.load(\"./models/real_best.pth\"))\n",
    "model.eval()\n",
    "\n",
    "X, y = shuffle(features, labels, random_state=1)\n",
    "\n",
    "test_inputs = X[843:]\n",
    "relevance_labels = y[843:] > 0.5\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_preds = model(torch.tensor(test_inputs).to(device).to(torch.float32))[0]\n",
    "    nonzero_indices = torch.tensor(y[843:]).to(\"cuda\").nonzero().split( 1, dim=1)\n",
    "    print(\"RMSE: \")\n",
    "    print(torch.sqrt(((torch.tensor(y[843:]).to(\"cuda\")[nonzero_indices] - test_preds[nonzero_indices]) ** 2).mean()))\n",
    "    print(\"Precision and Recall: \")\n",
    "    test_pred_labels = test_preds > .4\n",
    "    print(precision_recall_fscore_support(relevance_labels.flatten(), test_pred_labels.cpu().flatten(), average=\"binary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c47ff",
   "metadata": {},
   "source": [
    "# Demo Program Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a21d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_age(age):\n",
    "    age -= 34.05196182396607\n",
    "    age /= 12.1927397\n",
    "    return age\n",
    "\n",
    "movie_info = pd.read_csv(\"./data/Movielens100/u.item\", sep = \"|\", encoding='latin-1', names= [\"movie id\" , \"movie title\", \"release date\", \"video release date\",\n",
    "                                                                                        \"imdb_url\", \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Childrens\", \"Comedy\", \"Crime\",\n",
    "                                                                                        \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \n",
    "                                                                                        \"War\", \"Western\"], index_col = 0)\n",
    "movie_info.index -= 1\n",
    "movie_genres = movie_info.drop([\"movie title\", \"release date\", \"video release date\", \"imdb_url\"], axis=1)\n",
    "movie_genres = movie_genres.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f23646fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your age \n",
      "27\n",
      "-0.5783738517739427\n",
      "Enter your sex (M/F) \n",
      "M\n",
      "1\n",
      "How do you feel about Secret of Roan Inish, The (1994) ? (1 to 5, 3 if unfamiliar) \n",
      "3\n",
      "0\n",
      "How do you feel about Family Thing, A (1996) ? (1 to 5, 3 if unfamiliar) \n",
      "3\n",
      "0\n",
      "How do you feel about Jupiter's Wife (1994) ? (1 to 5, 3 if unfamiliar) \n",
      "3\n",
      "0\n",
      "How do you feel about One Night Stand (1997) ? (1 to 5, 3 if unfamiliar) \n",
      "5\n",
      "2\n",
      "How do you feel about Walking Dead, The (1995) ? (1 to 5, 3 if unfamiliar) \n",
      "5\n",
      "2\n",
      "How do you feel about Grace of My Heart (1996) ? (1 to 5, 3 if unfamiliar) \n",
      "5\n",
      "2\n",
      "How do you feel about 20,000 Leagues Under the Sea (1954) ? (1 to 5, 3 if unfamiliar) \n",
      "5\n",
      "2\n",
      "How do you feel about Family Thing, A (1996) ? (1 to 5, 3 if unfamiliar) \n",
      "5\n",
      "2\n",
      "How do you feel about Being There (1979) ? (1 to 5, 3 if unfamiliar) \n",
      "quit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Childrens</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unknown  Action  Adventure  Animation  Childrens  Comedy  Crime  \\\n",
       "0      0.0     0.0       0.25        0.0       0.25     0.5    0.0   \n",
       "\n",
       "   Documentary  Drama  Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  \\\n",
       "0          0.0    1.0     0.25        0.0     0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Sci-Fi  Thriller   War  Western  \n",
       "0    0.25       0.0  0.25      0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = input(\"Enter your age \\n\")\n",
    "age = normalize_age(int(age))\n",
    "print(age)\n",
    "sex = input(\"Enter your sex (M/F) \\n\")\n",
    "sex = 1 if sex == \"M\" else 0\n",
    "print(sex)\n",
    "ratings = {}\n",
    "user_ratings = np.zeros(1682)\n",
    "num_ratings = 0\n",
    "while(True):\n",
    "    movie_index = np.random.randint(1682)\n",
    "    response = input(\"How do you feel about \" + movie_info.loc[movie_index][\"movie title\"] + \" ? (1 to 5, 3 if unfamiliar) \\n\")\n",
    "    if (response == \"quit\"):\n",
    "        break\n",
    "    else:\n",
    "        response = int(response)\n",
    "        response -= 3\n",
    "        print(response)\n",
    "        user_ratings[movie_index] = response\n",
    "        num_ratings += 1 \n",
    "user_tastes = np.dot(movie_genres.T, user_ratings) / num_ratings\n",
    "pd.DataFrame([user_tastes], columns = [\"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Childrens\", \"Comedy\", \"Crime\",\"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91890a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = np.array([age, sex])\n",
    "user_info = np.concatenate((user_data, user_tastes))\n",
    "demo_features = np.concatenate((user_info, user_ratings))\n",
    "demo_features = np.array([demo_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddf3dfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.26588726e-01, -2.84439206e-01, -1.06312215e-01, ...,\n",
       "       -3.24324071e-02,  1.38729000e-02,  4.37286217e-05], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_preds = model(torch.tensor(demo_features).to(device).to(torch.float32))[0]\n",
    "test_preds = test_preds.cpu().numpy()[0]\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d73ab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top 10 rated movies are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "movie id\n",
       "290                                 Absolute Power (1997)\n",
       "468                                     Short Cuts (1993)\n",
       "255     When the Cats Away (Chacun cherche son chat) (...\n",
       "321                                 Murder at 1600 (1997)\n",
       "180                             Return of the Jedi (1983)\n",
       "301                              L.A. Confidential (1997)\n",
       "1382       Second Jungle Book: Mowgli & Baloo, The (1997)\n",
       "686                                  McHale's Navy (1997)\n",
       "159                            Glengarry Glen Ross (1992)\n",
       "124                                     Phenomenon (1996)\n",
       "Name: movie title, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Your top 10 rated movies are: \")\n",
    "top10_indices = np.flip(np.argsort(test_preds)[-10:])\n",
    "movie_info.loc[top10_indices][\"movie title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405e62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f565479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771104e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
